## æ·±åº¦å­¦ä¹ 

* [Tensorflow](https://www.tensorflow.org/) - ç«¯åˆ°ç«¯çš„å¼€æºæœºå™¨å­¦ä¹ å¹³å°
* [PyTorch](https://github.com/pytorch/pytorch) - Tensors and Dynamic neural networks in Python with strong GPU acceleration
    * https://pytorch.org/
* [PaddlePaddle](https://www.paddlepaddle.org.cn/) - æºäºäº§ä¸šå®è·µçš„å¼€æºæ·±åº¦å­¦ä¹ å¹³å°
* [Apache MXNet](https://mxnet.apache.org/) - A flexible and efficient library for deep learning.
* [Keras](https://keras.io/) - Deep Learning for humans
* [JAX](https://github.com/google/jax) - Composable transformations of Python+NumPy programs: differentiate, vectorize, JIT to GPU/TPU, and more
* [æ—·è§†å¤©å…ƒ MegEngine](https://www.megengine.org.cn/) - å›½äº§å¼€æºæ·±åº¦å­¦ä¹ æ¡†æ¶
    * [MegEngine/MegEngine](https://github.com/MegEngine/MegEngine) - ä¸€ä¸ªå¿«é€Ÿã€å¯æ‹“å±•ã€æ˜“äºä½¿ç”¨ä¸”æ”¯æŒè‡ªåŠ¨æ±‚å¯¼çš„æ·±åº¦å­¦ä¹ æ¡†æ¶
* [OneFlow æ·±åº¦å­¦ä¹ æ¡†æ¶](https://www.oneflow.org/a/chanpin/oneflow/) - ä¸€æµç§‘æŠ€æœ‰é™å…¬å¸
    * [Oneflow-Inc/oneflow](https://github.com/Oneflow-Inc/oneflow) - a deep learning framework designed to be user-friendly, scalable and efficient.
* [æ˜‡æ€ MindSpore](https://mindspore.cn/) - åä¸ºå¼€æºè‡ªç ”AIæ¡†æ¶
* [Caffe](https://github.com/BVLC/caffe) - a fast open framework for deep learning.
* [MNN](https://github.com/alibaba/MNN) - a blazing fast, lightweight deep learning framework, battle-tested by business-critical use cases in Alibaba

### æ·±åº¦ç¥ç»ç½‘ç»œ

* [An Introduction to Convolutional Neural Networks](https://arxiv.org/abs/1511.08458)
* [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)
* [Recurrent Neural Networks (RNNs): A gentle Introduction and Overview](https://arxiv.org/abs/1912.05911)
* [Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent Neural Networks](https://arxiv.org/abs/1909.09586)
* [Kolmogorov-Arnold Networks (KANs)](https://github.com/KindXiaoming/pykan)

### Tensorflow

* [Tensorflow ä¸­æ–‡](https://doc.codingdict.com/tensorflow/index-2.html)
* [Tensorflow æ•™ç¨‹](https://mofanpy.com/tutorials/machine-learning/tensorflow/)
* [deepmind/sonnet](https://github.com/deepmind/sonnet) - TensorFlow-based neural network library

### PyTorch

* [ã€ŠNatural Language Processing with PyTorchã€‹ä¸­æ–‡ç¿»è¯‘](https://nlp-pt.apachecn.org/)
* [ã€ŠPytorchå®ç”¨æ•™ç¨‹ã€‹ï¼ˆç¬¬äºŒç‰ˆï¼‰](https://github.com/TingsongYu/PyTorch-Tutorial-2nd)

### Transformers

* [Transformers](https://github.com/huggingface/transformers) - State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.
* [Transformers å¿«é€Ÿå…¥é—¨](https://transformers.run/)
* [xenova/transformers.js](https://github.com/xenova/transformers.js) - State-of-the-art Machine Learning for the web. Run Transformers directly in your browser, with no need for a server!
* [xFormers](https://github.com/facebookresearch/xformers) - Hackable and optimized Transformers building blocks, supporting a composable construction.

### æ¨¡å‹éƒ¨ç½²å’Œæ¨ç†

* [onnx](https://github.com/onnx/onnx) - Open standard for machine learning interoperability
* [ncnn](https://github.com/Tencent/ncnn) - a high-performance neural network inference framework optimized for the mobile platform
* [NVIDIA TensorRT](https://developer.nvidia.cn/tensorrt) - ç”¨äºé«˜æ€§èƒ½æ·±åº¦å­¦ä¹ æ¨ç†çš„ SDK
* [OpenVINO](https://github.com/openvinotoolkit/openvino) - an open-source toolkit for optimizing and deploying AI inference

### æœºå™¨å­¦ä¹ å¹³å°

* [tencentmusic/cube-studio](https://github.com/tencentmusic/cube-studio) - äº‘åŸç”Ÿä¸€ç«™å¼æœºå™¨å­¦ä¹ å¹³å°ï¼Œå¤šç§Ÿæˆ·ï¼Œæ•°æ®èµ„äº§ï¼Œnotebookåœ¨çº¿å¼€å‘ï¼Œæ‹–æ‹‰æ‹½ä»»åŠ¡æµç¼–æ’ï¼Œå¤šæœºå¤šå¡åˆ†å¸ƒå¼è®­ç»ƒï¼Œè¶…å‚æœç´¢ï¼Œæ¨ç†æœåŠ¡ï¼Œå¤šé›†ç¾¤è°ƒåº¦ï¼Œå¤šé¡¹ç›®ç»„èµ„æºç»„ï¼Œè¾¹ç¼˜è®¡ç®—ï¼Œå¤§æ¨¡å‹å®æ—¶è®­ç»ƒ, aiåº”ç”¨å•†åº—

## AI å†…æ ¸åº“

* [NCCL](https://github.com/NVIDIA/nccl) - Optimized primitives for collective multi-GPU communication
* [CUTLASS](https://github.com/NVIDIA/cutlass) - CUDA Templates and Python DSLs for High-Performance Linear Algebra
* [RAPIDS](https://github.com/rapidsai) - Open GPU Data Science
* [TransformerEngine](https://github.com/NVIDIA/TransformerEngine) - A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit and 4-bit floating point (FP8 and FP4) precision on Hopper, Ada and Blackwell GPUs, to provide better performance with lower memory utilization in both training and inference.
* [FlashInfer](https://github.com/flashinfer-ai/flashinfer) - Kernel Library for LLM Serving
* [FlashAttention](https://github.com/Dao-AILab/flash-attention) - Fast and memory-efficient exact attention
* [MLX](https://github.com/ml-explore/mlx) - An array framework for Apple silicon
* [DeepEP](https://github.com/deepseek-ai/DeepEP) - an efficient expert-parallel communication library

## AI ç¼–è¯‘å™¨

* [Triton](https://github.com/triton-lang/triton) - a language and compiler for writing highly efficient custom Deep-Learning primitives.
* [Modular](https://github.com/modular/modular) - A unified platform for AI development and deployment, including MAXğŸ§‘â€ğŸš€ and MojoğŸ”¥.
* [XLA](https://github.com/openxla/xla) - A machine learning compiler for GPUs, CPUs, and ML accelerators
