## 大数据

* [AllData](https://github.com/alldatacenter/alldata) - 可定义数据中台，以数据平台为底座，以数据中台为桥梁，以机器学习平台为中层框架，以大模型应用为上游产品，提供全链路数字化解决方案

### 数据集成

* [Airbyte](https://github.com/airbytehq/airbyte) - The leading data integration platform for ETL / ELT data pipelines from APIs, databases & files to data warehouses, data lakes & data lakehouses.
* [Dagster](https://github.com/dagster-io/dagster) - An orchestration platform for the development, production, and observation of data assets.
* [Apache Flume](https://flume.apache.org/) - Flume is a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of log data.
* [Apache SeaTunnel](https://seatunnel.apache.org/) - Next-generation high-performance, distributed, massive data integration tool.
* [Airbyte](https://github.com/airbytehq/airbyte) - Data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes.
* [Cube](https://github.com/cube-js/cube) - the semantic layer for building data applications
* [Trino](https://trino.io/) - Distributed SQL query engine for big data, formerly known as PrestoSQL
	* [trinodb/trino](https://github.com/trinodb/trino)
* [Apache Calcite](https://calcite.apache.org/) - Dynamic data management framework
* [DataCap](https://github.com/devlive-community/datacap) - integrated software for data transformation, integration, and visualization. Support a variety of data sources, file types, big data related database, relational database, NoSQL database, etc.

### 工作流调度

* [Apache Airflow](https://airflow.apache.org/) - A platform to programmatically author, schedule, and monitor workflows
* [Apache DolphinScheduler](https://dolphinscheduler.apache.org/zh-cn) - 是一个分布式和可扩展的开源工作流协调平台，具有强大的DAG可视化界面
* [dromara/disjob](https://github.com/dromara/disjob) - A distributed job scheduling framework
* [Prefect](https://github.com/PrefectHQ/prefect) - a workflow orchestration tool empowering developers to build, observe, and react to data pipelines
* [Flyte](https://github.com/flyteorg/flyte) - Scalable and flexible workflow orchestration platform that seamlessly unifies data, ML and analytics stacks.

### 流式处理

* [Apache Flink](https://flink.apache.org/) - Stateful Computations over Data Streams
* [Apache Pulsar](https://pulsar.apache.org/) - distributed pub-sub messaging system
* [StreamNative](https://streamnative.io/) - The unified messaging and streaming platform
* [RisingWave](https://github.com/risingwavelabs/risingwave) - The distributed streaming database: SQL stream processing with Postgres-like experience
* [Streamis](https://github.com/WeBankFinTech/Streamis/blob/main/README-ZH.md) - Streamis 是 微众银行 联合 天翼云、仙翁科技 和 萨摩耶云 联合共建的流式应用开发管理系统
* [DTStack/Taier](https://github.com/DTStack/Taier) - 太阿，一个开源的分布式 DAG 调度系统

### 数据仓库

* [Apache Doris](https://doris.apache.org/zh-CN/) - 简单易用、高性能和统一的分析数据库
* [ByConity](https://github.com/ByConity/ByConity) - an open source cloud data warehouse

### 数据治理

* [Datahub](https://github.com/datahub-project/datahub) - The Metadata Platform for your Data and AI Stack
* [OpenMetadata](https://github.com/open-metadata/OpenMetadata) - a unified metadata platform for data discovery, data observability, and data governance powered by a central metadata repository, in-depth column level lineage, and seamless team collaboration.
* [Apache Gravitino](https://github.com/apache/gravitino) - World's most powerful open data catalog for building a high-performance, geo-distributed and federated metadata lake.
* [Unity Catalog](https://github.com/unitycatalog/unitycatalog) - Open, Multimodal Catalog for Data & AI
* [dbt](https://github.com/dbt-labs/dbt-core) - enables data analysts and engineers to transform their data using the same practices that software engineers use to build applications.

### 数据湖

* [Apache Hudi](https://hudi.apache.org/) - an open data lakehouse platform, built on a high-performance open table format to bring database functionality to your data lakes. 
* [Apache Paimon](https://github.com/apache/paimon/) - a lake format that enables building a Realtime Lakehouse Architecture with Flink and Spark for both streaming and batch operations.
* [Delta Lake](https://github.com/delta-io/delta) - An open-source storage framework that enables building a Lakehouse architecture with compute engines including Spark, PrestoDB, Flink, Trino, and Hive and APIs

### 数据格式

* [Apache Arrow](https://arrow.apache.org/) - A cross-language development platform for in-memory analytics
* [Apache Parquet](https://parquet.apache.org/) - an open source, column-oriented data file format designed for efficient data storage and retrieval.
* [Apache Iceberg](https://iceberg.apache.org/) - The open table format for analytic datasets.
